import { debugGraph } from "./debug-utils";
import {
  generateAndInsertNodeEmbeddings,
  generateAndInsertEdgeEmbeddings,
} from "./embeddings-util";
import { formatNodesForPrompt } from "./formatting";
import { findSimilarNodes, findOneHopNodes } from "./graph";
import { TemporaryIdMapper } from "./temporary-id-mapper";
import { zodResponseFormat } from "openai/helpers/zod.mjs";
import { z } from "zod";
import { type DrizzleDB } from "~/db";
import { edges, nodeMetadata, nodes } from "~/db/schema";
import { EdgeTypeEnum, NodeTypeEnum, SourceType } from "~/types/graph";
import { type TypeId } from "~/types/typeid";
import { useDatabase } from "~/utils/db";

const llmNodeSchema = z.object({
  id: z.string().describe("id to reference in edges"),
  type: NodeTypeEnum.describe("one of the allowed node types"),
  label: z.string().describe("human-readable name/title"),
  description: z.string().describe("longer text description").optional(),
});
type LlmOutputNode = z.infer<typeof llmNodeSchema>;

const llmEdgeSchema = z.object({
  sourceId: z.string().describe("id of staring node"),
  targetId: z.string().describe("id of ending node"),
  type: EdgeTypeEnum.describe("one of the allowed edge types"),
  description: z
    .string()
    .describe("short description of the edge (if it represents a 'fact')")
    .optional(),
});
type LlmOutputEdge = z.infer<typeof llmEdgeSchema>;

interface NodeForLLMPrompt {
  id: string;
  type: z.infer<typeof NodeTypeEnum>;
  label: string | null;
  timestamp: string;
  description?: string | null;
  tempId: string;
}

interface ProcessedNode {
  id: TypeId<"node">;
  label: string;
  description: string | undefined;
  nodeType: z.infer<typeof NodeTypeEnum>;
}

interface SimilarNodeForPrompt {
  id: TypeId<"node">;
  type: z.infer<typeof NodeTypeEnum>;
  label: string | null;
  description: string | null;
  timestamp: string;
}

interface ExtractGraphParams {
  userId: string;
  sourceType: SourceType;
  linkedNodeId: TypeId<"node">;
  content: string;
}

// --- Main extractGraph function ---
export async function extractGraph({
  userId,
  sourceType,
  linkedNodeId,
  content,
}: ExtractGraphParams) {
  const db = await useDatabase();

  const similarNodesRaw = (
    await Promise.all([
      findSimilarNodes({
        userId,
        text: content,
        limit: 50,
        minimumSimilarity: 0.3,
      }),
      findOneHopNodes(db, userId, [linkedNodeId]),
    ])
  ).flat();

  const similarNodesForProcessing = similarNodesRaw.map((node) => ({
    id: node.id,
    type: node.type,
    label: node.label,
    description: node.description,
    timestamp: node.timestamp.toISOString(),
  }));

  const { nodesForPromptFormatting, idMap, nodeLabels } =
    _prepareInitialNodeMappings(similarNodesForProcessing);

  const { createCompletionClient } = await import("./ai");
  const client = await createCompletionClient(userId);

  const prompt = `You are a knowledge graph extraction expert. Your task is to analyze the following ${sourceType} and extract entities, concepts, events, and their relationships to create a knowledge graph.

IMPORTANT:
- Do NOT respond to the content. Instead, analyze it and extract a structured graph representation.
${
  nodesForPromptFormatting.length > 0
    ? `
- Do NOT extract anything from the contextâ€”only from the ${sourceType} given at the end. The context is only provided to help you understand the ${sourceType} better.
- I've provided some existing nodes that may be relevant to this ${sourceType}. If any of these nodes match entities in the ${sourceType}, use their 'tempId' (e.g., existing_person_1) in your 'nodes' or 'edges' if you refer to them. DO NOT create new nodes for these if they match.

<context>
${formatNodesForPrompt(nodesForPromptFormatting)}
</context>
`
    : ""
}

Extract the graph from the following ${sourceType}:

<${sourceType}>
${content}
</${sourceType}>

CRITICAL EXTRACTION RULES - READ CAREFULLY:

When extracting from conversations:
- ONLY extract facts that the USER explicitly stated, confirmed, or provided
- DO NOT extract speculative statements, suggestions, or assumptions made by the assistant
- DO NOT treat assistant's questions as facts (e.g., "Are you working on X?" is NOT a fact that the user is working on X)
- DO NOT extract assistant's interpretations unless the user confirmed them
- If the assistant makes a statement and the user corrects it, ONLY extract the user's correction as fact
- Prioritize user's own statements about themselves, their experiences, preferences, and circumstances
- Be especially cautious with information only mentioned by the assistant - verify if the user confirmed it

Extract, for example, the following elements:
1. People mentioned by the user (real or fictional)
2. Locations the user discussed or mentioned
3. Events that the user stated occurred or experienced
4. Objects or items the user mentioned as significant
5. Emotions the user expressed or discussed
6. Concepts or ideas the user explored or mentioned
7. Media the user mentioned (books, movies, articles, etc.)
8. Temporal references the user provided (dates, times, periods)
9. The user's preferences, goals, projects, and plans
10. Facts the user stated about other people or entities

For each element, create a node with:
- A unique temporary ID (format: "temp_[type]_[number]", e.g., "temp_person_1") if it's a NEW node.
- The appropriate node type
- A concise label (name/title)
- A brief description providing context (optional)

Then, link these nodes with edges.
- Edges are mainly used to represent "facts" about nodes. For example, if you have a Person node and an Event node, you can create an edge from the Person node to the Event node to represent the fact that the person participated in the event.
- ONLY create edges for facts explicitly stated by the user, not assistant assumptions
- Edges are unique by source node, target node, and edge type
- In the edge description for facts, give a succinct description of the fact. Add some minimal context to aid retrieval, but keep it concise.
- Ideally, edges link to already-existing nodes. If the node isn't existing, create it.

Rules of the graph:
- Nodes are unique by type and label
- Never create new nodes for a node that already exists
- In node names use full names, eg. "John Doe" instead of "John"
- Omit unnecessary details in node names, eg. "John Doe" instead of "John Doe (person)"
- Nodes are independent of context and represent a *single* thing. Bad example: "John - the person taking a walk". Good example: "John" (Person node, no description) linked to [PARTICIPATED_IN] "John's walk on 2025-05-18" (Event node), linked to [OCCURRED_ON] "2025-05-18" (Temporal node).
- Don't create nodes for things that should be represented by edges.
- Avoid redundant or duplicate information - if a fact is already represented, don't create another node or edge for it

Then create edges between these nodes to represent their relationships using the appropriate edge types.

Focus on extracting the most significant and meaningful information that the USER provided. Quality and accuracy are more important than quantity.`;

  const completion = await client.beta.chat.completions.parse({
    messages: [{ role: "user", content: prompt }],
    model: env.MODEL_ID_GRAPH_EXTRACTION,
    response_format: zodResponseFormat(
      z.object({
        nodes: z.array(llmNodeSchema),
        edges: z.array(llmEdgeSchema),
      }),
      "subgraph",
    ),
  });

  const parsedLlmOutput = completion.choices[0]?.message.parsed;
  if (!parsedLlmOutput) {
    throw new Error("Failed to parse LLM response");
  }

  const uniqueParsedLlmNodes = _deduplicateLlmNodes(parsedLlmOutput.nodes);
  const uniqueParsedLlmEdges = _deduplicateLlmEdges(parsedLlmOutput.edges);

  const detailsOfNewlyCreatedNodes = await _processAndInsertNewNodes(
    db,
    userId,
    uniqueParsedLlmNodes,
    idMap,
    nodeLabels,
  );

  // Create edges linking new nodes to the provided linkedNodeId
  if (linkedNodeId && detailsOfNewlyCreatedNodes.length > 0) {
    await db
      .insert(edges)
      .values(
        detailsOfNewlyCreatedNodes.map((newNode) => ({
          userId,
          sourceNodeId: newNode.id,
          targetNodeId: linkedNodeId,
          edgeType: EdgeTypeEnum.enum.MENTIONED_IN,
          description: null,
        })),
      )
      .onConflictDoNothing();
  }

  const insertedEdgeRecords = await _processAndInsertLlmEdges(
    db,
    userId,
    uniqueParsedLlmEdges,
    idMap,
  );

  const edgesToEmbed = insertedEdgeRecords
    .map((edgeRecord) => {
      const sourceLabel = nodeLabels.get(edgeRecord.sourceNodeId);
      const targetLabel = nodeLabels.get(edgeRecord.targetNodeId);

      if (!sourceLabel || !targetLabel || !edgeRecord.description) return null;

      return {
        edgeId: edgeRecord.id,
        edgeType: edgeRecord.edgeType,
        description: edgeRecord.description,
        sourceLabel,
        targetLabel,
      };
    })
    .filter((e): e is NonNullable<typeof e> => e !== null);

  await Promise.all([
    generateAndInsertEdgeEmbeddings(db, edgesToEmbed),
    generateAndInsertNodeEmbeddings(db, detailsOfNewlyCreatedNodes),
  ]);

  debugGraph(detailsOfNewlyCreatedNodes, insertedEdgeRecords);

  return {
    newNodesCreated: detailsOfNewlyCreatedNodes.length,
    edgesCreated: insertedEdgeRecords.length,
  };
}

function _deduplicateLlmNodes(llmNodes: LlmOutputNode[]): LlmOutputNode[] {
  const seen = new Set<string>();
  return llmNodes.filter((node) => {
    if (seen.has(node.id)) return false;
    seen.add(node.id);
    return true;
  });
}

function _deduplicateLlmEdges(llmEdges: LlmOutputEdge[]): LlmOutputEdge[] {
  const seenEdgeKeys = new Set<string>();
  return llmEdges.filter((e) => {
    const key = `${e.sourceId}|${e.targetId}|${e.type}`;
    if (seenEdgeKeys.has(key)) return false;
    seenEdgeKeys.add(key);
    return true;
  });
}

function _prepareInitialNodeMappings(similarNodes: SimilarNodeForPrompt[]) {
  const existingNodeMapper = new TemporaryIdMapper<
    SimilarNodeForPrompt,
    string
  >((item, index) => `existing_${item.type.toLowerCase()}_${index + 1}`);

  const mappedExistingNodes = existingNodeMapper.mapItems(similarNodes);

  const idMap = new Map<string, TypeId<"node">>();
  const nodeLabels = new Map<TypeId<"node">, string>();

  for (const mappedNode of mappedExistingNodes) {
    idMap.set(mappedNode.tempId, mappedNode.id);
    idMap.set(mappedNode.id.toString(), mappedNode.id);
    if (mappedNode.label) {
      nodeLabels.set(mappedNode.id, mappedNode.label);
    }
  }

  const nodesForPromptFormatting: NodeForLLMPrompt[] = mappedExistingNodes.map(
    (mappedNode) => ({
      id: mappedNode.id.toString(),
      type: mappedNode.type,
      label: mappedNode.label,
      description: mappedNode.description,
      tempId: mappedNode.tempId,
      timestamp: mappedNode.timestamp,
    }),
  );

  return { nodesForPromptFormatting, idMap, nodeLabels };
}

async function _processAndInsertNewNodes(
  db: DrizzleDB,
  userId: string,
  uniqueParsedLlmNodes: LlmOutputNode[],
  idMap: Map<string, TypeId<"node">>,
  nodeLabels: Map<TypeId<"node">, string>,
): Promise<ProcessedNode[]> {
  const detailsOfNewlyCreatedNodes: ProcessedNode[] = [];

  for (const llmNode of uniqueParsedLlmNodes) {
    if (idMap.has(llmNode.id)) {
      continue;
    }

    const [insertedNodeRecord] = await db
      .insert(nodes)
      .values({
        userId,
        nodeType: llmNode.type,
      })
      .returning();

    if (!insertedNodeRecord) {
      console.warn(`Failed to insert node: ${llmNode.label}`);
      continue;
    }

    await db.insert(nodeMetadata).values({
      nodeId: insertedNodeRecord.id,
      label: llmNode.label,
      description: llmNode.description,
      additionalData: {},
    });

    idMap.set(llmNode.id, insertedNodeRecord.id);
    nodeLabels.set(insertedNodeRecord.id, llmNode.label);

    detailsOfNewlyCreatedNodes.push({
      id: insertedNodeRecord.id,
      label: llmNode.label,
      description: llmNode.description,
      nodeType: llmNode.type,
    });
  }
  return detailsOfNewlyCreatedNodes;
}

async function _processAndInsertLlmEdges(
  db: DrizzleDB,
  userId: string,
  uniqueParsedLlmEdges: LlmOutputEdge[],
  idMap: Map<string, TypeId<"node">>,
): Promise<Array<typeof edges.$inferSelect>> {
  const edgeInserts: Array<typeof edges.$inferInsert> = [];

  for (const llmEdge of uniqueParsedLlmEdges) {
    const sourceNodeId = idMap.get(llmEdge.sourceId);
    const targetNodeId = idMap.get(llmEdge.targetId);

    if (!sourceNodeId || !targetNodeId) {
      console.warn(
        `Skipping edge with invalid node references: ${llmEdge.sourceId} -> ${llmEdge.targetId}`,
      );
      continue;
    }

    edgeInserts.push({
      userId,
      sourceNodeId,
      targetNodeId,
      edgeType: llmEdge.type,
      description: llmEdge.description,
    });
  }

  if (edgeInserts.length === 0) {
    return [];
  }

  const insertedEdgeRecords = await db
    .insert(edges)
    .values(edgeInserts)
    .onConflictDoNothing({
      target: [edges.sourceNodeId, edges.targetNodeId, edges.edgeType],
    })
    .returning();

  return insertedEdgeRecords;
}
